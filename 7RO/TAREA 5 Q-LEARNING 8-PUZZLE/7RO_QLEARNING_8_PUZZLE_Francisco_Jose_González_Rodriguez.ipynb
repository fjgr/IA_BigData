{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f8cb91d3e09494e9f2cd98474be6b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0129897671b4562a185dbad2641b843",
              "IPY_MODEL_1b6c9c5281ee4f178a9947f67bff4cb1",
              "IPY_MODEL_aee8f362674142679f878d2808ba83eb"
            ],
            "layout": "IPY_MODEL_c1a0eb98706c4627934d0e986a7db13d"
          }
        },
        "e0129897671b4562a185dbad2641b843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_174d8025186442ea9ebbc5924fc49fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_62d76583de55460cb6b1f310ebe5a08f",
            "value": "  2%"
          }
        },
        "1b6c9c5281ee4f178a9947f67bff4cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b04378c487441afb48295262d8ed59b",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_700c512b42cc4a78b75e904714674e98",
            "value": 1036
          }
        },
        "aee8f362674142679f878d2808ba83eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd88617a7e9a422cbfb9d8815d3da532",
            "placeholder": "​",
            "style": "IPY_MODEL_1a8c4ffed77c4ed39ac96f165b9d68b6",
            "value": " 1036/50000 [00:42&lt;32:58, 24.74it/s]"
          }
        },
        "c1a0eb98706c4627934d0e986a7db13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174d8025186442ea9ebbc5924fc49fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d76583de55460cb6b1f310ebe5a08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b04378c487441afb48295262d8ed59b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700c512b42cc4a78b75e904714674e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd88617a7e9a422cbfb9d8815d3da532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a8c4ffed77c4ed39ac96f165b9d68b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjgr/IA_BigData/blob/main/7RO/TAREA%205%20Q-LEARNING%208-PUZZLE/7RO_QLEARNING_8_PUZZLE_Francisco_Jose_Gonz%C3%A1lez_Rodriguez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Índice:\n",
        "1. [Preparar el entorno y las dependencias](#preparar-entorno)\n",
        "2. [Definir configuraciones y clases auxiliares](#definir-configuraciones)\n",
        "3. [Implementar el entrenamiento](#implementar-entrenamiento)\n",
        "4. [Resolver el problema](#resolver-problema)\n",
        "5. [Ejecutar el programa principal](#ejecutar-programa-principal)\n"
      ],
      "metadata": {
        "id": "ykikVu3QxlqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.  Preparar el entorno y las dependencias\n",
        "<a name=\"preparar-entorno\"></a>"
      ],
      "metadata": {
        "id": "4y_lfcPwbwiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, display, HTML\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import random"
      ],
      "metadata": {
        "id": "6vDXn2jjMM8H"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.   Definir configuraciones y clases auxiliares\n",
        "<a name=\"definir-configuraciones\"></a>"
      ],
      "metadata": {
        "id": "Tcj5s2XYcKly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase de configuración y utilidades de visualización\n",
        "@dataclass\n",
        "class QLearningConfig:\n",
        "    \"\"\"\n",
        "    Clase para almacenar parámetros de configuración para el algoritmo de Q-Learning.\n",
        "\n",
        "    Atributos:\n",
        "        - learning_rate: Tasa de aprendizaje para actualizar la tabla Q.\n",
        "        - gamma: Factor de descuento para valorar recompensas futuras.\n",
        "        - initial_epsilon: Probabilidad inicial de exploración.\n",
        "        - epsilon_min: Límite inferior para epsilon durante el entrenamiento.\n",
        "        - epsilon_decay: Factor de decaimiento de epsilon por episodio.\n",
        "        - max_episodes: Número máximo de episodios de entrenamiento.\n",
        "        - save_path: Ruta donde se guardan los datos entrenados.\n",
        "        - checkpoint_interval: Episodios entre guardados de modelo.\n",
        "    \"\"\"\n",
        "    learning_rate: float = 0.8\n",
        "    gamma: float = 0.9\n",
        "    initial_epsilon: float = 1.0\n",
        "    epsilon_min: float = 0.1\n",
        "    epsilon_decay: float = 0.995\n",
        "    max_episodes: int = 50_000\n",
        "    save_path: str = \"/content/q_learning_data\"\n",
        "    checkpoint_interval: int = 5_000\n",
        "\n",
        "def display_puzzle_state(state: str, title: str = \"\"):\n",
        "    \"\"\"\n",
        "    Visualiza el estado actual del tablero del 8-puzzle en formato HTML.\n",
        "\n",
        "    Args:\n",
        "        state: Representación del tablero como una cadena de texto.\n",
        "        title: Título opcional para mostrar junto al tablero.\n",
        "    \"\"\"\n",
        "    html = f\"\"\"\n",
        "    <div style=\"font-family: monospace; padding: 10px;\">\n",
        "        <h4 style=\"margin: 0;\">{title}</h4>\n",
        "        <div style=\"border: 2px solid black; display: inline-block; padding: 5px; margin-top: 5px;\">\n",
        "            <table style=\"border-collapse: collapse;\">\n",
        "    \"\"\"\n",
        "\n",
        "    # Construcción del tablero en formato HTML\n",
        "    for i in range(0, 9, 3):\n",
        "        html += \"<tr>\"\n",
        "        for j in range(3):\n",
        "            value = state[i + j]\n",
        "            background = \"#e6f3ff\" if value == \"9\" else \"white\"\n",
        "            html += f'<td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: {background};\">{value}</td>'\n",
        "        html += \"</tr>\"\n",
        "\n",
        "    html += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(html))\n"
      ],
      "metadata": {
        "id": "pOnJpOeHcbUp"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.   Implementar el entrenamiento\n",
        "<a name=\"implementar-entrenamiento\"></a>\n",
        "\n"
      ],
      "metadata": {
        "id": "Szsr0AQ1cwmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase para gestionar el entrenamiento del modelo\n",
        "class EightPuzzleTrainer:\n",
        "    \"\"\"\n",
        "    Clase para entrenar un modelo de Q-Learning que resuelve el problema del 8-puzzle.\n",
        "\n",
        "    Atributos y métodos:\n",
        "        - DIRECTIONS: Direcciones posibles del movimiento.\n",
        "        - GOAL_STATE: Estado objetivo del rompecabezas.\n",
        "        - Métodos para inicializar, entrenar y guardar/recuperar estados.\n",
        "    \"\"\"\n",
        "\n",
        "    DIRECTIONS = [-3, 1, 3, -1]  # Arriba, Derecha, Abajo, Izquierda\n",
        "    GOAL_STATE = \"123456789\"\n",
        "\n",
        "    def __init__(self, config: QLearningConfig):\n",
        "        \"\"\"\n",
        "        Inicializa el entrenador del modelo.\n",
        "\n",
        "        Args:\n",
        "            config: Parámetros de configuración para el entrenamiento.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.transitions: Dict[str, List[Optional[str]]] = {}\n",
        "        self.q_table: Dict[str, Dict[int, float]] = {}\n",
        "        self._ensure_save_directory()\n",
        "\n",
        "    def _ensure_save_directory(self) -> None:\n",
        "        \"\"\"\n",
        "        Crea el directorio de guardado si no existe.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.config.save_path):\n",
        "            os.makedirs(self.config.save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def swap(state: str, i: int, j: int) -> str:\n",
        "        \"\"\"\n",
        "        Intercambia dos posiciones en el estado del tablero.\n",
        "\n",
        "        Args:\n",
        "            state: Estado actual del tablero.\n",
        "            i: Índice de la posición a intercambiar.\n",
        "            j: Índice de la posición a intercambiar.\n",
        "\n",
        "        Returns:\n",
        "            Nuevo estado del tablero con los elementos intercambiados.\n",
        "        \"\"\"\n",
        "        state_list = list(state)\n",
        "        state_list[i], state_list[j] = state_list[j], state_list[i]\n",
        "        return ''.join(state_list)\n",
        "\n",
        "    def is_valid_move(self, index: int, direction: int) -> bool:\n",
        "        \"\"\"\n",
        "        Verifica si un movimiento es válido dado el índice del espacio vacío y la dirección.\n",
        "\n",
        "        Args:\n",
        "            index: Índice de la posición vacía.\n",
        "            direction: Dirección del movimiento.\n",
        "\n",
        "        Returns:\n",
        "            True si el movimiento es válido, False de lo contrario.\n",
        "        \"\"\"\n",
        "        if direction == -3 and index < 3:  return False  # Arriba desde la primera fila\n",
        "        if direction == 3 and index > 5:   return False  # Abajo desde la última fila\n",
        "        if direction == -1 and index % 3 == 0: return False  # Izquierda desde la primera columna\n",
        "        if direction == 1 and index % 3 == 2:  return False  # Derecha desde la última columna\n",
        "        return True\n",
        "\n",
        "    def generate_transitions(self, initial_state: str) -> None:\n",
        "        \"\"\"\n",
        "        Genera todas las posibles transiciones desde un estado inicial utilizando BFS.\n",
        "\n",
        "        Args:\n",
        "            initial_state: Estado inicial del tablero.\n",
        "        \"\"\"\n",
        "        visited = set()\n",
        "        queue = deque([initial_state])\n",
        "\n",
        "        while queue:\n",
        "            current_state = queue.popleft()\n",
        "            if current_state in visited:\n",
        "                continue\n",
        "\n",
        "            visited.add(current_state)\n",
        "            empty_index = current_state.index('9')\n",
        "            state_transitions = []\n",
        "\n",
        "            for direction in self.DIRECTIONS:\n",
        "                if self.is_valid_move(empty_index, direction):\n",
        "                    new_state = self.swap(current_state, empty_index, empty_index + direction)\n",
        "                    state_transitions.append(new_state)\n",
        "                    if new_state not in visited:\n",
        "                        queue.append(new_state)\n",
        "                else:\n",
        "                    state_transitions.append(None)\n",
        "\n",
        "            self.transitions[current_state] = state_transitions\n",
        "\n",
        "    def initialize_q_table(self) -> None:\n",
        "        \"\"\"\n",
        "        Inicializa la tabla Q con ceros.\n",
        "        \"\"\"\n",
        "        self.q_table = {\n",
        "            state: {action: 0.0 for action in range(4)}\n",
        "            for state in self.transitions\n",
        "        }\n",
        "\n",
        "    def calculate_reward(self, state: str, next_state: str, visited_states: set) -> float:\n",
        "        \"\"\"\n",
        "        Calcula la recompensa basada en la distancia de Manhattan y penalizaciones.\n",
        "\n",
        "        Args:\n",
        "            state: Estado actual del tablero.\n",
        "            next_state: Próximo estado del tablero.\n",
        "            visited_states: Conjunto de estados visitados previamente.\n",
        "\n",
        "        Returns:\n",
        "            Valor de recompensa calculado.\n",
        "        \"\"\"\n",
        "        def manhattan_distance(state: str) -> int:\n",
        "            distance = 0\n",
        "            for i, digit in enumerate(state):\n",
        "                if digit == '9':\n",
        "                    continue\n",
        "                current_row, current_col = i // 3, i % 3\n",
        "                goal_idx = int(digit) - 1\n",
        "                goal_row, goal_col = goal_idx // 3, goal_idx % 3\n",
        "                distance += abs(current_row - goal_row) + abs(current_col - goal_col)\n",
        "            return distance\n",
        "\n",
        "        if state == self.GOAL_STATE:\n",
        "            return 1000\n",
        "\n",
        "        current_distance = manhattan_distance(state)\n",
        "        next_distance = manhattan_distance(next_state)\n",
        "\n",
        "        distance_reward = (current_distance - next_distance) * 10\n",
        "        loop_penalty = -50 if next_state in visited_states else 0\n",
        "        progress_penalty = -5 if next_distance >= current_distance else 0\n",
        "\n",
        "        return distance_reward + loop_penalty + progress_penalty\n",
        "\n",
        "    def save_checkpoint(self, episode: int) -> None:\n",
        "        \"\"\"\n",
        "        Guarda un punto de control del modelo.\n",
        "\n",
        "        Args:\n",
        "            episode: Número de episodio actual.\n",
        "        \"\"\"\n",
        "        checkpoint_path = os.path.join(\n",
        "            self.config.save_path,\n",
        "            f'checkpoint_episode_{episode}.json'\n",
        "        )\n",
        "        data = {\n",
        "            'episode': episode,\n",
        "            'q_table': self.q_table,\n",
        "            'transitions': self.transitions\n",
        "        }\n",
        "        with open(checkpoint_path, 'w') as f:\n",
        "            json.dump(data, f)\n",
        "\n",
        "    def load_latest_checkpoint(self) -> Optional[int]:\n",
        "        \"\"\"\n",
        "        Carga el punto de control más reciente si existe.\n",
        "\n",
        "        Returns:\n",
        "            Número del último episodio si se carga correctamente, None de lo contrario.\n",
        "        \"\"\"\n",
        "        checkpoints = [f for f in os.listdir(self.config.save_path)\n",
        "                      if f.startswith('checkpoint_episode_')]\n",
        "        if not checkpoints:\n",
        "            return None\n",
        "\n",
        "        latest = max(checkpoints)\n",
        "        with open(os.path.join(self.config.save_path, latest), 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.q_table = data['q_table']\n",
        "            self.transitions = data['transitions']\n",
        "            return data['episode']\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"\"\"\n",
        "        Entrena el modelo de Q-Learning.\n",
        "        \"\"\"\n",
        "        print(\"Generando transiciones...\")\n",
        "        self.generate_transitions(self.GOAL_STATE)\n",
        "        print(f\"Generados {len(self.transitions)} estados\")\n",
        "\n",
        "        print(\"Inicializando tabla Q...\")\n",
        "        self.initialize_q_table()\n",
        "\n",
        "        epsilon = self.config.initial_epsilon\n",
        "        states = list(self.transitions.keys())\n",
        "\n",
        "        best_performance = float('-inf')\n",
        "        no_improvement_count = 0\n",
        "\n",
        "        print(\"Comenzando episodios de entrenamiento...\")\n",
        "        for episode in tqdm(range(self.config.max_episodes)):\n",
        "            current_state = np.random.choice(states)\n",
        "            visited_states = set()\n",
        "            step_count = 0\n",
        "            episode_reward = 0\n",
        "\n",
        "            while step_count < 20:  # Máximo de 20 pasos por episodio\n",
        "                visited_states.add(current_state)\n",
        "\n",
        "                valid_actions = [\n",
        "                    a for a in range(4)\n",
        "                    if self.transitions[current_state][a] is not None\n",
        "                ]\n",
        "\n",
        "                if not valid_actions:\n",
        "                    break\n",
        "\n",
        "                if np.random.rand() < epsilon:\n",
        "                    action = np.random.choice(valid_actions)\n",
        "                else:\n",
        "                    action = max(valid_actions,\n",
        "                               key=lambda a: self.q_table[current_state][a])\n",
        "\n",
        "                next_state = self.transitions[current_state][action]\n",
        "                reward = self.calculate_reward(current_state, next_state, visited_states)\n",
        "                episode_reward += reward\n",
        "\n",
        "                self.q_table[current_state][action] = (\n",
        "                    (1 - self.config.learning_rate) * self.q_table[current_state][action] +\n",
        "                    self.config.learning_rate * (\n",
        "                        reward +\n",
        "                        self.config.gamma * max(self.q_table[next_state].values())\n",
        "                    )\n",
        "                )\n",
        "\n",
        "                if next_state == self.GOAL_STATE:\n",
        "                    break\n",
        "\n",
        "                current_state = next_state\n",
        "                step_count += 1\n",
        "\n",
        "            if episode_reward > best_performance:\n",
        "                best_performance = episode_reward\n",
        "                no_improvement_count = 0\n",
        "            else:\n",
        "                no_improvement_count += 1\n",
        "\n",
        "            if no_improvement_count > 1000:\n",
        "                print(f\"\\nTerminación temprana en el episodio {episode} debido a falta de mejoras\")\n",
        "                break\n",
        "\n",
        "            epsilon = max(\n",
        "                self.config.epsilon_min,\n",
        "                epsilon * self.config.epsilon_decay\n",
        "            )\n",
        "\n",
        "            if episode > 0 and episode % self.config.checkpoint_interval == 0:\n",
        "                self.save_checkpoint(episode)\n",
        "                print(f\"\\nPunto de control guardado en el episodio {episode}\")\n",
        "                print(f\"Epsilon actual: {epsilon:.4f}\")\n",
        "\n",
        "        print(\"Entrenamiento completado!\")"
      ],
      "metadata": {
        "id": "5BqtCxikdCKq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.  Resolver el problema\n",
        "<a name=\"resolver-problema\"></a>"
      ],
      "metadata": {
        "id": "A29OGhNNfhoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase para resolver el puzzle con el modelo entrenado\n",
        "class EightPuzzleSolver:\n",
        "    \"\"\"\n",
        "    Clase de solucionador mejorada con búsqueda de ruta mejorada y prevención de bucles\n",
        "    \"\"\"\n",
        "    def __init__(self, trainer: EightPuzzleTrainer):\n",
        "        self.trainer = trainer\n",
        "        self.move_names = {-3: \"UP\", 1: \"RIGHT\", 3: \"DOWN\", -1: \"LEFT\"}\n",
        "\n",
        "    def get_manhattan_distance(self, state: str) -> int:\n",
        "        \"\"\"\n",
        "        Calcula la distancia de Manhattan entre el estado actual y el estado objetivo.\n",
        "        Esta métrica suma las distancias de cada número a su posición correcta.\n",
        "\n",
        "        Args:\n",
        "            state: Estado actual del puzzle como cadena.\n",
        "\n",
        "        Returns:\n",
        "            Distancia total de Manhattan.\n",
        "        \"\"\"\n",
        "        distance = 0\n",
        "        for i, digit in enumerate(state):\n",
        "            if digit != '9':\n",
        "                current_row, current_col = i // 3, i % 3\n",
        "                goal_idx = int(digit) - 1\n",
        "                goal_row, goal_col = goal_idx // 3, goal_idx % 3\n",
        "                distance += abs(current_row - goal_row) + abs(current_col - goal_col)\n",
        "        return distance\n",
        "\n",
        "    def evaluate_move(self, state: str, action: int, visited_states: set) -> float:\n",
        "        \"\"\"\n",
        "        Evalúa la calidad de un movimiento considerando múltiples factores:\n",
        "        - Valor Q del entrenamiento\n",
        "        - Penalización por estados ya visitados\n",
        "        - Mejora en la distancia al objetivo\n",
        "        - Bonificación por movimientos no intentados recientemente\n",
        "        \"\"\"\n",
        "        next_state = self.trainer.transitions[state][action]\n",
        "        if next_state is None:\n",
        "            return float('-inf')\n",
        "\n",
        "        # Base Q-value from training\n",
        "        q_value = self.trainer.q_table[state][action]\n",
        "\n",
        "        # Penalties and bonuses\n",
        "        visit_penalty = -100 if next_state in visited_states else 0\n",
        "        current_distance = self.get_manhattan_distance(state)\n",
        "        next_distance = self.get_manhattan_distance(next_state)\n",
        "        distance_improvement = (current_distance - next_distance) * 20\n",
        "\n",
        "        # Bonus for moves that haven't been tried recently\n",
        "        recency_bonus = 0 if next_state in visited_states else 50\n",
        "\n",
        "        return q_value + visit_penalty + distance_improvement + recency_bonus\n",
        "\n",
        "    def solve(self, initial_state: str, max_steps: int = 1000) -> List[str]:\n",
        "        \"\"\"\n",
        "        Resuelve el puzzle utilizando una estrategia mejorada de selección de movimientos\n",
        "        y prevención de bucles.\n",
        "\n",
        "        Características:\n",
        "        - Detecta cuando se queda atascado y aumenta la exploración\n",
        "        - Visualiza cada paso con información detallada\n",
        "        - Considera la distancia Manhattan para evaluar el progreso\n",
        "        - Implementa mecanismos para evitar bucles\n",
        "        \"\"\"\n",
        "        if not self.trainer.q_table:\n",
        "            raise ValueError(\"No hay ningún modelo entrenado disponible\")\n",
        "\n",
        "        if not self.is_solvable(initial_state):\n",
        "            print(\"Advertencia: ¡Esta configuración de rompecabezas no tiene solución!\")\n",
        "            return []\n",
        "\n",
        "        path = []\n",
        "        visited_states = set()\n",
        "        current_state = initial_state\n",
        "        stuck_counter = 0\n",
        "        last_distance = float('inf')\n",
        "\n",
        "        print(\"\\nEstado inicial:\")\n",
        "        display_puzzle_state(current_state, \"Posición inicial\")\n",
        "        time.sleep(1)\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            path.append(current_state)\n",
        "            visited_states.add(current_state)\n",
        "\n",
        "            if current_state == self.trainer.GOAL_STATE:\n",
        "                print(f\"\\nSolución encontrada en {step} pasos!\")\n",
        "                display_puzzle_state(current_state, f\"¡Objetivo alcanzado! (Pasos {step})\")\n",
        "                return path\n",
        "\n",
        "            # Get all valid actions and their evaluations\n",
        "            valid_actions = []\n",
        "            action_values = {}\n",
        "\n",
        "            for action in range(4):\n",
        "                next_state = self.trainer.transitions[current_state][action]\n",
        "                if next_state is not None:\n",
        "                    move_value = self.evaluate_move(current_state, action, visited_states)\n",
        "                    action_values[action] = move_value\n",
        "                    valid_actions.append(action)\n",
        "\n",
        "            if not valid_actions:\n",
        "                print(\"No valid moves available\")\n",
        "                break\n",
        "\n",
        "            # Select best action considering various factors\n",
        "            current_distance = self.get_manhattan_distance(current_state)\n",
        "\n",
        "            # Check if we're stuck\n",
        "            if current_distance >= last_distance:\n",
        "                stuck_counter += 1\n",
        "            else:\n",
        "                stuck_counter = 0\n",
        "            last_distance = current_distance\n",
        "\n",
        "            # If stuck, increase exploration\n",
        "            if stuck_counter > 3:\n",
        "                # Choose a random action that leads to an unvisited state\n",
        "                unvisited_actions = [a for a in valid_actions\n",
        "                                   if self.trainer.transitions[current_state][a] not in visited_states]\n",
        "                if unvisited_actions:\n",
        "                    action = random.choice(unvisited_actions)\n",
        "                else:\n",
        "                    action = random.choice(valid_actions)\n",
        "                stuck_counter = 0\n",
        "            else:\n",
        "                # Choose the best action based on evaluations\n",
        "                action = max(action_values.keys(), key=lambda a: action_values[a])\n",
        "\n",
        "            next_state = self.trainer.transitions[current_state][action]\n",
        "            move_name = self.move_names[self.trainer.DIRECTIONS[action]]\n",
        "\n",
        "            clear_output(wait=True)\n",
        "            print(f\"\\nPaso {step + 1}:\")\n",
        "            print(f\"Movimiento: {move_name}\")\n",
        "            print(f\"Manhattan distancia a la meta: {current_distance}\")\n",
        "            display_puzzle_state(current_state, f\"Estado actual (anterior {move_name})\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            current_state = next_state\n",
        "\n",
        "        print(\"\\nNo se pudo resolver dentro del límite de pasos\")\n",
        "        return path\n",
        "\n",
        "    @staticmethod\n",
        "    def is_solvable(state: str) -> bool:\n",
        "        \"\"\"Determinar si el estado del rompecabezas es solucionable\"\"\"\n",
        "        numbers = [int(x) for x in state if x != '9']\n",
        "        inversions = sum(1 for i in range(len(numbers))\n",
        "                        for j in range(i + 1, len(numbers))\n",
        "                        if numbers[i] > numbers[j])\n",
        "        return inversions % 2 == 0\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_random_initial_state() -> str:\n",
        "        \"\"\"Generar un estado inicial aleatorio solucionable\"\"\"\n",
        "        while True:\n",
        "            state = ''.join(random.sample(\"123456789\", 9))\n",
        "            if EightPuzzleSolver.is_solvable(state):\n",
        "                return state\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Función principal para configurar el entorno, entrenar el modelo y resolver el puzzle.\n",
        "    \"\"\"\n",
        "    print(\"Configurando entorno de entrenamiento...\")\n",
        "    config = QLearningConfig()\n",
        "    trainer = EightPuzzleTrainer(config)\n",
        "\n",
        "    print(\"\\nGenerando estado inicial aleatorio válido...\")\n",
        "    # Call generate_random_initial_state from EightPuzzleSolver instead of EightPuzzleTrainer\n",
        "    # Corrected line: Calling is_solvable from EightPuzzleSolver\n",
        "    initial_state = EightPuzzleSolver.generate_random_initial_state()\n",
        "    print(f\"Estado inicial generado: {initial_state}\")\n",
        "\n",
        "    print(\"\\nIniciando proceso de entrenamiento...\")\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"\\nEntrenamiento completado. Iniciando solución del puzzle...\")\n",
        "    solver = EightPuzzleSolver(trainer)\n",
        "\n",
        "    print(\"\\nResolviendo el puzzle...\")\n",
        "    solution_path = solver.solve(initial_state)\n",
        "\n",
        "    print(\"\\nEstadísticas de la solución:\")\n",
        "    print(f\"Movimientos totales: {len(solution_path) - 1}\")\n",
        "    print(f\"Estados únicos visitados: {len(set(solution_path))}\")\n",
        "    print(f\"Estado objetivo alcanzado: {'Sí' if solution_path[-1] == trainer.GOAL_STATE else 'No'}\")"
      ],
      "metadata": {
        "id": "urSexg40fr5W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.  Ejecutar el programa principal\n",
        "<a name=\"ejecutar-programa-principal\"></a>"
      ],
      "metadata": {
        "id": "rDo1XweQyDIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the main function\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "0f8cb91d3e09494e9f2cd98474be6b47",
            "e0129897671b4562a185dbad2641b843",
            "1b6c9c5281ee4f178a9947f67bff4cb1",
            "aee8f362674142679f878d2808ba83eb",
            "c1a0eb98706c4627934d0e986a7db13d",
            "174d8025186442ea9ebbc5924fc49fe8",
            "62d76583de55460cb6b1f310ebe5a08f",
            "3b04378c487441afb48295262d8ed59b",
            "700c512b42cc4a78b75e904714674e98",
            "cd88617a7e9a422cbfb9d8815d3da532",
            "1a8c4ffed77c4ed39ac96f165b9d68b6"
          ]
        },
        "id": "ygCfHzQ7f4e4",
        "outputId": "993436bd-0070-4c9a-a3c9-61e3e8b3e1e6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 100:\n",
            "Move: UP\n",
            "Manhattan distance to goal: 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"font-family: monospace; padding: 10px;\">\n",
              "        <h4 style=\"margin: 0;\">Current state (before UP)</h4>\n",
              "        <div style=\"border: 2px solid black; display: inline-block; padding: 5px; margin-top: 5px;\">\n",
              "            <table style=\"border-collapse: collapse;\">\n",
              "    <tr><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">4</td><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">3</td><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">2</td></tr><tr><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">1</td><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">8</td><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: #e6f3ff;\">9</td></tr><tr><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">5</td><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">7</td><td style=\"border: 1px solid black; width: 30px; height: 30px; text-align: center; background-color: white;\">6</td></tr>\n",
              "            </table>\n",
              "        </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Could not solve within step limit\n",
            "\n",
            "Estadísticas de la solución:\n",
            "Movimientos totales: 99\n",
            "Estados únicos visitados: 99\n",
            "Estado objetivo alcanzado: No\n"
          ]
        }
      ]
    }
  ]
}